{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TwistedGrims/sdfsdf32423dsfsdzxvczxfweqr2314/blob/main/imagegenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Imports + google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!pip install -U xformers\n",
        "from IPython.display import display\n",
        "import torch\n",
        "import random\n",
        "from diffusers import (\n",
        "    StableDiffusionXLPipeline,\n",
        "    EulerAncestralDiscreteScheduler,\n",
        "    EulerDiscreteScheduler,\n",
        "    DDIMScheduler,\n",
        "    DPMSolverMultistepScheduler,\n",
        ")\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "clear_output(wait=True)\n"
      ],
      "metadata": {
        "id": "TQffshqinWLb",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # load checkpoints\n",
        "\n",
        "\n",
        "checkpoint = \"nova3dcgxl\" #@param[\"nova3dcgxl\",\"nsfwillustrious\",\"pornmaster\"]\n",
        "checkpoint_paths = {\n",
        "    \"pornmaster\": \"/content/gdrive/MyDrive/Pmaster.safetensors\",\n",
        "    \"nsfwillustrious\": \"/content/gdrive/MyDrive/NSFWillustrious.safetensors\",\n",
        "    \"nova3dcgxl\": \"/content/gdrive/MyDrive/nova3DCGXL_illustriousV60.safetensors\"\n",
        "}\n",
        "\n",
        "model_path = checkpoint_paths[checkpoint]\n",
        "pipe = StableDiffusionXLPipeline.from_single_file(\n",
        "    model_path,\n",
        "    torch_dtype=torch.float16\n",
        ").to(\"cuda\")\n",
        "\n",
        "pipe.enable_xformers_memory_efficient_attention()\n",
        "pipe.enable_vae_slicing()\n",
        "#pipe.enable_sequential_cpu_offload()\n",
        "clear_output(wait=True)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "WEk2qEUhceZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import time\n",
        "prompt = \"masterpiece, best quality, amazing quality, explicit, from side, profile, 2girls, solo, turquoise hair, high ponytail, heterochromia, red eyes, blue eyes, glowing eyes, eyebrows, eyelashes, head tilt, nipples, latex dress, side slit, outdoors, standing on balcony, overlooking futuristic city, neon lights reflecting, streets below, holographic billboards, glowing advertisements, night cityscape, cyberpunk atmosphere, soft ambient glow, intricate details, blurry background\"  #@param {type:\"string\"}\n",
        "negative_prompt = \"child, loli, patreon logo, bad quality, worst quality, worst detail, sketch, censor, censored, watermark, signature, blurry, plain simple background, blank eyes, messy hair, hydrokinesis, earrings, facial tattoo,\"  #@param {type:\"string\"}\n",
        "firsttime =time.time()\n",
        "aspect_ratios = {\n",
        "    \"Square\": (512,512),\n",
        "    \"Landscape\": (1216, 832),\n",
        "    \"Portrait\": (832, 1216)\n",
        "}\n",
        "chosen_ratio = \"Square\"  #@param [\"Square\", \"Landscape\", \"Portrait\"]\n",
        "width, height = aspect_ratios[chosen_ratio]\n",
        "cfg_scale = 4  #@param {type:\"number\"}\n",
        "steps = 20  #@param {type:\"integer\"}\n",
        "seed = 0  #@param {type:\"integer\"}\n",
        "\n",
        "if seed and seed > 0:\n",
        "    current_seed = seed\n",
        "else:\n",
        "    current_seed = random.randint(0, 2**32 - 1)\n",
        "\n",
        "generator = torch.Generator(device=\"cuda\").manual_seed(current_seed)\n",
        "\n",
        "def callback(step: int, timestep: int, latents):\n",
        "    with torch.no_grad():\n",
        "        image = pipe.vae.decode(latents / pipe.vae.config.scaling_factor).sample\n",
        "        image = (image / 2 + 0.5).clamp(0, 1)\n",
        "        image = (image * 255).permute(0, 2, 3, 1).cpu().numpy().astype(\"uint8\")[0]\n",
        "        pil_img = Image.fromarray(image)\n",
        "        preview = pil_img.copy()\n",
        "        preview.thumbnail((width//2, height//2), Image.LANCZOS)\n",
        "        clear_output(wait=True)\n",
        "        display(preview)\n",
        "        print(f\"Step {step+1}/{steps}\")\n",
        "\n",
        "result = pipe(\n",
        "    prompt=prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    width=width,\n",
        "    height=height,\n",
        "    num_inference_steps=steps,\n",
        "    guidance_scale=cfg_scale,\n",
        "    generator=generator,\n",
        "    callback=callback,\n",
        "    callback_steps=1\n",
        ")\n",
        "\n",
        "clear_output(wait=True)\n",
        "display(result.images[0])\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "print(f\"took {(time.time()-firsttime):.2f} seconds\")"
      ],
      "metadata": {
        "id": "FtCwqNyjnYZF",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}